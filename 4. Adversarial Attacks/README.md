### **Project 4: Adversarial Attacks on DNNs**

One of the challenges of deep learning models is adversarial attacks and robustness of models to these attacks.
In these attacks, the class of the input image is changed by making changes on the input image that cannot be easily recognized by humans.
In this project, Fast gradient signal method (FGSM) attack and how to deal with it has been investigated.
